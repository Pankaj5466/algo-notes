\documentclass{../latex-setting/cmemoir}
\usepackage{scrextend}
\usepackage{minitoc}
\usepackage{shortvrb}


% NEW

\newcommand{\lstart}{\begin{compactenum}}
\newcommand{\lend}{\end{compactenum}}
\renewcommand{\i}{\item}
\renewcommand{\r}{\reply}

\newcommand{\reply}[1]{R: #1 }

% NEW END
% Question-Anser Summary Commands
\newcounter{qcount}

\newcommand{\qicon}{\faQuestion\hspace{.3cm}}
\newcommand{\sicon}{\\\faLightbulb\hspace{.3cm}}


\newenvironment{question}[1]
{
    \stepcounter{qcount}
    \textbf{(\theqcount) #1}
    \addcontentsline{toc}{subsection}{#1} % 
    \begin{addmargin}[2cm]{0cm}
}
{\end{addmargin}}

\newcommand{\qq}{}



\begin{document}
\tableofcontents


\chapter{Web Crawler}


\begin{exercise}[Web Crawler Design Question/Summary:]
\begin{enumerate}
    \item What is a web crawler system? 
    \item Given some example in which internet is explored for specific purpose.
    \item How many pages will the crawler will process  approximalely? (reply: 1B per month)
    \item What do we need to store?
    
\end{enumerate}

\end{exercise}

\qicon What do we need to store?
\sicon HTML only for now.

\qicon How long we need to store the crawl result?
\sicon Lets assume we need to store 5year worth of data.



\newpage
\label{answers}
\begin{question}{What is a web crawler?}
   
    A web crawerl is a system that explores the word wide web (internet) to carry out specific task. Some of the examples what normall web-crawlers are used are:
    \begin{compactenum}[(i)]
        \item Index Generation for search gian like google,yahoo etc.
        \item Taking a time-snapshot of world wide web for archival or library purpose.
        \item Detect copyright infrignment.
        \item Detect sensitive code re-usage by anyone on the web.
        \item Extract specific images for modal training.
        \item etc \dots
    \end{compactenum}

\end{question}

\qq { What are the systems that gets involved in desinging a large application?}


\include{crawler.tex}

\end{document}